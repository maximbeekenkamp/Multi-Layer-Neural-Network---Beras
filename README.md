# Multi-Layer-Neural-Network---Beras

Using the MNIST handwritten digits dataset to train a simple classification neural network using batch learning. 
This project Beras (haha) is a personal implementation of Keras, and is intended to learn how tensorflow works
by implementing its components using numpy. Beras is a complete overhaul of tensorflow, and includes the preprocessing, 
optimizers, intializers, Dense layers etc.

My implementation of Beras has an accuracy of 91.58% on a single layer model, and an accuracy of 97.59% on a multi-layer model.
The implementation of SoftMax is the only known bug of the model.
